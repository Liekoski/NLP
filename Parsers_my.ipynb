{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import subprocess\n",
    "import sys\n",
    "from nltk import Nonterminal, nonterminals, Production, CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt1 = Nonterminal('NP')\n",
    "nt2 = Nonterminal('VP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NP'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt1.symbol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt1 == Nonterminal('NP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt1 == nt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вводим компоненты правила"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "S, NP, VP, PP = nonterminals('S, NP, VP, PP')\n",
    "N, V, P, DT = nonterminals('N, V, P, DT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Левые и правые части правила:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod1 = Production(S, [NP, VP])\n",
    "prod2 = Production(NP, [DT, NP])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спрашиваются части у правила"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod1.lhs() #левая часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(NP, VP)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod1.rhs() #правая часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod1 == Production(S, [NP, VP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod1 == prod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = CFG.fromstring(\"\"\"\n",
    "... S -> NP VP\n",
    "... PP -> P NP\n",
    "... NP -> 'the' N | N PP | 'the' N PP\n",
    "... VP -> V NP | V PP | V NP PP\n",
    "... N -> 'cat'\n",
    "... N -> 'dog'\n",
    "... N -> 'rug'\n",
    "... V -> 'chased'\n",
    "... V -> 'sat'\n",
    "... P -> 'in'\n",
    "... P -> 'on'\n",
    "... \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"\"\"import pickle\n",
    "... from nltk import Production\n",
    "... p = Production('S', ['NP', 'VP'])\n",
    "... print(pickle.dumps(p))\n",
    "... \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Start a subprocess to simulate pickling in another process\n",
    "proc = subprocess.run([sys.executable, '-c', cmd], stdout=subprocess.PIPE)\n",
    "p1 = pickle.loads(eval(proc.stdout))\n",
    "p2 = Production('S', ['NP', 'VP'])\n",
    "print(hash(p1) == hash(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import RecursiveDescentParser #метод рекурсивного спуска (парсинг сверху-вниз)\n",
    "rd = RecursiveDescentParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = 'the cat chased the dog'.split()\n",
    "sentence2 = 'the cat chased the dog on the rug'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP the (N cat)) (VP (V chased) (NP the (N dog))))\n"
     ]
    }
   ],
   "source": [
    "for t in rd.parse(sentence1):\n",
    "     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the (N cat))\n",
      "  (VP (V chased) (NP the (N dog) (PP (P on) (NP the (N rug))))))\n",
      "(S\n",
      "  (NP the (N cat))\n",
      "  (VP (V chased) (NP the (N dog)) (PP (P on) (NP the (N rug)))))\n"
     ]
    }
   ],
   "source": [
    "for t in rd.parse(sentence2): #кошку догнала собака на ковре или кошка догнала собаку, из-за этого 2 варианта\n",
    "     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import ShiftReduceParser\n",
    "sr = ShiftReduceParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = 'the cat chased the dog'.split()\n",
    "sentence2 = 'the cat chased the dog on the rug'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP the (N cat)) (VP (V chased) (NP the (N dog))))\n"
     ]
    }
   ],
   "source": [
    "for t in sr.parse(sentence1):\n",
    "     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in sr.parse(sentence2):\n",
    "     print(t) #тут он ничего не выводит, потому что он зашёл в тупик, так как нет одного решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw a dog\n",
      "['I', 'saw', 'a', 'dog']\n",
      "\n",
      "* Strategy: Bottom-up\n",
      "\n",
      "|.    I    .   saw   .    a    .   dog   .|\n",
      "|[---------]         .         .         .| [0:1] 'I'\n",
      "|.         [---------]         .         .| [1:2] 'saw'\n",
      "|.         .         [---------]         .| [2:3] 'a'\n",
      "|.         .         .         [---------]| [3:4] 'dog'\n",
      "|>         .         .         .         .| [0:0] NP -> * 'I'\n",
      "|[---------]         .         .         .| [0:1] NP -> 'I' *\n",
      "|>         .         .         .         .| [0:0] S  -> * NP VP\n",
      "|>         .         .         .         .| [0:0] NP -> * NP PP\n",
      "|[--------->         .         .         .| [0:1] S  -> NP * VP\n",
      "|[--------->         .         .         .| [0:1] NP -> NP * PP\n",
      "|.         >         .         .         .| [1:1] Verb -> * 'saw'\n",
      "|.         [---------]         .         .| [1:2] Verb -> 'saw' *\n",
      "|.         >         .         .         .| [1:1] VP -> * Verb NP\n",
      "|.         >         .         .         .| [1:1] VP -> * Verb\n",
      "|.         [--------->         .         .| [1:2] VP -> Verb * NP\n",
      "|.         [---------]         .         .| [1:2] VP -> Verb *\n",
      "|.         >         .         .         .| [1:1] VP -> * VP PP\n",
      "|[-------------------]         .         .| [0:2] S  -> NP VP *\n",
      "|.         [--------->         .         .| [1:2] VP -> VP * PP\n",
      "|.         .         >         .         .| [2:2] Det -> * 'a'\n",
      "|.         .         [---------]         .| [2:3] Det -> 'a' *\n",
      "|.         .         >         .         .| [2:2] NP -> * Det Noun\n",
      "|.         .         [--------->         .| [2:3] NP -> Det * Noun\n",
      "|.         .         .         >         .| [3:3] Noun -> * 'dog'\n",
      "|.         .         .         [---------]| [3:4] Noun -> 'dog' *\n",
      "|.         .         [-------------------]| [2:4] NP -> Det Noun *\n",
      "|.         .         >         .         .| [2:2] S  -> * NP VP\n",
      "|.         .         >         .         .| [2:2] NP -> * NP PP\n",
      "|.         [-----------------------------]| [1:4] VP -> Verb NP *\n",
      "|.         .         [------------------->| [2:4] S  -> NP * VP\n",
      "|.         .         [------------------->| [2:4] NP -> NP * PP\n",
      "|[=======================================]| [0:4] S  -> NP VP *\n",
      "|.         [----------------------------->| [1:4] VP -> VP * PP\n",
      "Nr edges in chart: 33\n",
      "(S (NP I) (VP (Verb saw) (NP (Det a) (Noun dog))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.parse.chart.demo(2, print_times=False, trace=1,\n",
    "                       sent='I saw a dog', numparses=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw John with a dog\n",
      "['I', 'saw', 'John', 'with', 'a', 'dog']\n",
      "\n",
      "* Strategy: Top-down\n",
      "\n",
      "Nr edges in chart: 48\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.parse.chart.demo(1, print_times=False, trace=0,\n",
    "                       sent='I saw John with a dog', numparses=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw John with a dog\n",
      "['I', 'saw', 'John', 'with', 'a', 'dog']\n",
      "\n",
      "* Strategy: Bottom-up\n",
      "\n",
      "Nr edges in chart: 53\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.parse.chart.demo(2, print_times=False, trace=0,\n",
    "                       sent='I saw John with a dog', numparses=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw John with a dog\n",
      "['I', 'saw', 'John', 'with', 'a', 'dog']\n",
      "\n",
      "* Strategy: Bottom-up left-corner\n",
      "\n",
      "Nr edges in chart: 36\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.parse.chart.demo(3, print_times=False, trace=0,\n",
    "                      sent='I saw John with a dog', numparses=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw John with a dog\n",
      "['I', 'saw', 'John', 'with', 'a', 'dog']\n",
      "\n",
      "* Strategy: Filtered left-corner\n",
      "\n",
      "Nr edges in chart: 28\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.parse.chart.demo(4, print_times=False, trace=0,\n",
    "                       sent='I saw John with a dog', numparses=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw John with a dog\n",
      "['I', 'saw', 'John', 'with', 'a', 'dog']\n",
      "\n",
      "* Strategy: Stepping (top-down vs bottom-up)\n",
      "\n",
      "*** SWITCH TO TOP DOWN\n",
      "|[------]      .      .      .      .      .| [0:1] 'I'\n",
      "|.      [------]      .      .      .      .| [1:2] 'saw'\n",
      "|.      .      [------]      .      .      .| [2:3] 'John'\n",
      "|.      .      .      [------]      .      .| [3:4] 'with'\n",
      "|.      .      .      .      [------]      .| [4:5] 'a'\n",
      "|.      .      .      .      .      [------]| [5:6] 'dog'\n",
      "|>      .      .      .      .      .      .| [0:0] S  -> * NP VP\n",
      "|>      .      .      .      .      .      .| [0:0] NP -> * NP PP\n",
      "|>      .      .      .      .      .      .| [0:0] NP -> * Det Noun\n",
      "|>      .      .      .      .      .      .| [0:0] NP -> * 'I'\n",
      "|[------]      .      .      .      .      .| [0:1] NP -> 'I' *\n",
      "|[------>      .      .      .      .      .| [0:1] S  -> NP * VP\n",
      "|[------>      .      .      .      .      .| [0:1] NP -> NP * PP\n",
      "|.      >      .      .      .      .      .| [1:1] VP -> * VP PP\n",
      "|.      >      .      .      .      .      .| [1:1] VP -> * Verb NP\n",
      "|.      >      .      .      .      .      .| [1:1] VP -> * Verb\n",
      "|.      >      .      .      .      .      .| [1:1] Verb -> * 'saw'\n",
      "|.      [------]      .      .      .      .| [1:2] Verb -> 'saw' *\n",
      "|.      [------>      .      .      .      .| [1:2] VP -> Verb * NP\n",
      "|.      [------]      .      .      .      .| [1:2] VP -> Verb *\n",
      "|[-------------]      .      .      .      .| [0:2] S  -> NP VP *\n",
      "|.      [------>      .      .      .      .| [1:2] VP -> VP * PP\n",
      "*** SWITCH TO BOTTOM UP\n",
      "|.      .      >      .      .      .      .| [2:2] NP -> * 'John'\n",
      "|.      .      .      >      .      .      .| [3:3] PP -> * 'with' NP\n",
      "|.      .      .      >      .      .      .| [3:3] Prep -> * 'with'\n",
      "|.      .      .      .      >      .      .| [4:4] Det -> * 'a'\n",
      "|.      .      .      .      .      >      .| [5:5] Noun -> * 'dog'\n",
      "|.      .      [------]      .      .      .| [2:3] NP -> 'John' *\n",
      "|.      .      .      [------>      .      .| [3:4] PP -> 'with' * NP\n",
      "|.      .      .      [------]      .      .| [3:4] Prep -> 'with' *\n",
      "|.      .      .      .      [------]      .| [4:5] Det -> 'a' *\n",
      "|.      .      .      .      .      [------]| [5:6] Noun -> 'dog' *\n",
      "|.      [-------------]      .      .      .| [1:3] VP -> Verb NP *\n",
      "|[--------------------]      .      .      .| [0:3] S  -> NP VP *\n",
      "|.      [------------->      .      .      .| [1:3] VP -> VP * PP\n",
      "|.      .      >      .      .      .      .| [2:2] S  -> * NP VP\n",
      "|.      .      >      .      .      .      .| [2:2] NP -> * NP PP\n",
      "|.      .      .      .      >      .      .| [4:4] NP -> * Det Noun\n",
      "|.      .      [------>      .      .      .| [2:3] S  -> NP * VP\n",
      "|.      .      [------>      .      .      .| [2:3] NP -> NP * PP\n",
      "|.      .      .      .      [------>      .| [4:5] NP -> Det * Noun\n",
      "|.      .      .      .      [-------------]| [4:6] NP -> Det Noun *\n",
      "|.      .      .      [--------------------]| [3:6] PP -> 'with' NP *\n",
      "|.      [----------------------------------]| [1:6] VP -> VP PP *\n",
      "*** SWITCH TO TOP DOWN\n",
      "|.      .      >      .      .      .      .| [2:2] NP -> * Det Noun\n",
      "|.      .      .      .      >      .      .| [4:4] NP -> * NP PP\n",
      "|.      .      .      >      .      .      .| [3:3] VP -> * VP PP\n",
      "|.      .      .      >      .      .      .| [3:3] VP -> * Verb NP\n",
      "|.      .      .      >      .      .      .| [3:3] VP -> * Verb\n",
      "|[=========================================]| [0:6] S  -> NP VP *\n",
      "|.      [---------------------------------->| [1:6] VP -> VP * PP\n",
      "|.      .      [---------------------------]| [2:6] NP -> NP PP *\n",
      "|.      .      .      .      [------------->| [4:6] NP -> NP * PP\n",
      "|.      [----------------------------------]| [1:6] VP -> Verb NP *\n",
      "|.      .      [--------------------------->| [2:6] S  -> NP * VP\n",
      "|.      .      [--------------------------->| [2:6] NP -> NP * PP\n",
      "|[=========================================]| [0:6] S  -> NP VP *\n",
      "|.      [---------------------------------->| [1:6] VP -> VP * PP\n",
      "|.      .      .      .      .      .      >| [6:6] VP -> * VP PP\n",
      "|.      .      .      .      .      .      >| [6:6] VP -> * Verb NP\n",
      "|.      .      .      .      .      .      >| [6:6] VP -> * Verb\n",
      "*** SWITCH TO BOTTOM UP\n",
      "|.      .      .      .      >      .      .| [4:4] S  -> * NP VP\n",
      "|.      .      .      .      [------------->| [4:6] S  -> NP * VP\n",
      "*** SWITCH TO TOP DOWN\n",
      "*** SWITCH TO BOTTOM UP\n",
      "*** SWITCH TO TOP DOWN\n",
      "*** SWITCH TO BOTTOM UP\n",
      "*** SWITCH TO TOP DOWN\n",
      "*** SWITCH TO BOTTOM UP\n",
      "Nr edges in chart: 61\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk.parse.chart.demo(5, print_times=False, trace=1,\n",
    "                       sent='I saw John with a dog', numparses=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Sentence:\n",
      "I saw John with a dog\n",
      "['I', 'saw', 'John', 'with', 'a', 'dog']\n",
      "\n",
      "|.  I   . saw  . John . with .  a   . dog  .|\n",
      "|[------]      .      .      .      .      .| [0:1] 'I'\n",
      "|.      [------]      .      .      .      .| [1:2] 'saw'\n",
      "|.      .      [------]      .      .      .| [2:3] 'John'\n",
      "|.      .      .      [------]      .      .| [3:4] 'with'\n",
      "|.      .      .      .      [------]      .| [4:5] 'a'\n",
      "|.      .      .      .      .      [------]| [5:6] 'dog'\n",
      "|>      .      .      .      .      .      .| [0:0] S  -> * NP VP\n",
      "|>      .      .      .      .      .      .| [0:0] NP -> * NP PP\n",
      "|>      .      .      .      .      .      .| [0:0] NP -> * Det Noun\n",
      "|>      .      .      .      .      .      .| [0:0] NP -> * 'I'\n",
      "|[------]      .      .      .      .      .| [0:1] NP -> 'I' *\n",
      "|[------>      .      .      .      .      .| [0:1] S  -> NP * VP\n",
      "|[------>      .      .      .      .      .| [0:1] NP -> NP * PP\n",
      "|.      >      .      .      .      .      .| [1:1] VP -> * VP PP\n",
      "|.      >      .      .      .      .      .| [1:1] VP -> * Verb NP\n",
      "|.      >      .      .      .      .      .| [1:1] VP -> * Verb\n",
      "|.      >      .      .      .      .      .| [1:1] Verb -> * 'saw'\n",
      "|.      [------]      .      .      .      .| [1:2] Verb -> 'saw' *\n",
      "|.      [------>      .      .      .      .| [1:2] VP -> Verb * NP\n",
      "|.      [------]      .      .      .      .| [1:2] VP -> Verb *\n",
      "|[-------------]      .      .      .      .| [0:2] S  -> NP VP *\n",
      "|.      [------>      .      .      .      .| [1:2] VP -> VP * PP\n",
      "|.      .      >      .      .      .      .| [2:2] NP -> * NP PP\n",
      "|.      .      >      .      .      .      .| [2:2] NP -> * Det Noun\n",
      "|.      .      >      .      .      .      .| [2:2] NP -> * 'John'\n",
      "|.      .      [------]      .      .      .| [2:3] NP -> 'John' *\n",
      "|.      [-------------]      .      .      .| [1:3] VP -> Verb NP *\n",
      "|.      .      [------>      .      .      .| [2:3] NP -> NP * PP\n",
      "|.      .      .      >      .      .      .| [3:3] PP -> * 'with' NP\n",
      "|[--------------------]      .      .      .| [0:3] S  -> NP VP *\n",
      "|.      [------------->      .      .      .| [1:3] VP -> VP * PP\n",
      "|.      .      .      [------>      .      .| [3:4] PP -> 'with' * NP\n",
      "|.      .      .      .      >      .      .| [4:4] NP -> * NP PP\n",
      "|.      .      .      .      >      .      .| [4:4] NP -> * Det Noun\n",
      "|.      .      .      .      >      .      .| [4:4] Det -> * 'a'\n",
      "|.      .      .      .      [------]      .| [4:5] Det -> 'a' *\n",
      "|.      .      .      .      [------>      .| [4:5] NP -> Det * Noun\n",
      "|.      .      .      .      .      >      .| [5:5] Noun -> * 'dog'\n",
      "|.      .      .      .      .      [------]| [5:6] Noun -> 'dog' *\n",
      "|.      .      .      .      [-------------]| [4:6] NP -> Det Noun *\n",
      "|.      .      .      [--------------------]| [3:6] PP -> 'with' NP *\n",
      "|.      .      .      .      [------------->| [4:6] NP -> NP * PP\n",
      "|.      .      [---------------------------]| [2:6] NP -> NP PP *\n",
      "|.      [----------------------------------]| [1:6] VP -> VP PP *\n",
      "|[=========================================]| [0:6] S  -> NP VP *\n",
      "|.      [---------------------------------->| [1:6] VP -> VP * PP\n",
      "|.      [----------------------------------]| [1:6] VP -> Verb NP *\n",
      "|.      .      [--------------------------->| [2:6] NP -> NP * PP\n",
      "|[=========================================]| [0:6] S  -> NP VP *\n",
      "|.      [---------------------------------->| [1:6] VP -> VP * PP\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (VP (Verb saw) (NP John)) (PP with (NP (Det a) (Noun dog)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP (Verb saw) (NP (NP John) (PP with (NP (Det a) (Noun dog))))))\n"
     ]
    }
   ],
   "source": [
    "nltk.parse.earleychart.demo(print_times=False, trace=1,\n",
    "                             sent='I saw John with a dog', numparses=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "from itertools import islice\n",
    "from nltk.grammar import PCFG, induce_pcfg\n",
    "toy_pcfg1 = PCFG.fromstring(\"\"\"\n",
    "     S -> NP VP [1.0]\n",
    "     NP -> Det N [0.5] | NP PP [0.25] | 'John' [0.1] | 'I' [0.15]\n",
    "     Det -> 'the' [0.8] | 'my' [0.2]\n",
    "     N -> 'man' [0.5] | 'telescope' [0.5]\n",
    "     VP -> VP PP [0.1] | V NP [0.7] | V [0.2]\n",
    "     V -> 'ate' [0.35] | 'saw' [0.65]\n",
    "     PP -> P NP [1.0]\n",
    "     P -> 'with' [0.61] | 'under' [0.39]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_pcfg2 = PCFG.fromstring(\"\"\"\n",
    "     S    -> NP VP         [1.0]\n",
    "     VP   -> V NP          [.59]\n",
    "     VP   -> V             [.40]\n",
    "     VP   -> VP PP         [.01]\n",
    "     NP   -> Det N         [.41]\n",
    "     NP   -> Name          [.28]\n",
    "     NP   -> NP PP         [.31]\n",
    "     PP   -> P NP          [1.0]\n",
    "     V    -> 'saw'         [.21]\n",
    "     V    -> 'ate'         [.51]\n",
    "     V    -> 'ran'         [.28]\n",
    "     N    -> 'boy'         [.11]\n",
    "     N    -> 'cookie'      [.12]\n",
    "     N    -> 'table'       [.13]\n",
    "     N    -> 'telescope'   [.14]\n",
    "     N    -> 'hill'        [.5]\n",
    "     Name -> 'Jack'        [.52]\n",
    "     Name -> 'Bob'         [.48]\n",
    "     P    -> 'with'        [.61]\n",
    "     P    -> 'under'       [.39]\n",
    "     Det  -> 'the'         [.41]\n",
    "     Det  -> 'a'           [.31]\n",
    "     Det  -> 'my'          [.28]\n",
    "     \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A -> B B [0.3]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = PCFG.fromstring(\"\"\"\n",
    "... A -> B B [.3] | C B C [.7]\n",
    "... B -> B D [.5] | C [.5]\n",
    "... C -> 'a' [.1] | 'b' [0.9]\n",
    "... D -> 'b' [1.0]\n",
    "... \"\"\")\n",
    "prod = grammar.productions()[0]\n",
    "prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.lhs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(B, B)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod.rhs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "print((prod.prob()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[A -> B B [0.3],\n",
       " A -> C B C [0.7],\n",
       " B -> B D [0.5],\n",
       " B -> C [0.5],\n",
       " C -> 'a' [0.1],\n",
       " C -> 'b' [0.9],\n",
       " D -> 'b' [1.0]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar.productions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\DarkLord\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = []\n",
    "for fileid in treebank.fileids()[:2]:\n",
    "     for t in treebank.parsed_sents(fileid):\n",
    "         productions += t.productions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 71 productions>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = induce_pcfg(S, productions)\n",
    "grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PP -> IN NP [1.0]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grammar.productions(lhs=Nonterminal('PP')))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NNP -> 'Agnew' [0.0714286], NNP -> 'Consolidated' [0.0714286]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grammar.productions(lhs=Nonterminal('NNP')))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[JJ -> 'British' [0.142857], JJ -> 'former' [0.142857]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grammar.productions(lhs=Nonterminal('JJ')))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NP -> CD NNS [0.133333], NP -> DT JJ JJ NN [0.0666667]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(grammar.productions(lhs=Nonterminal('NP')))[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 23 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    VP -> V NP [0.59]\n",
      "    VP -> V [0.4]\n",
      "    VP -> VP PP [0.01]\n",
      "    NP -> Det N [0.41]\n",
      "    NP -> Name [0.28]\n",
      "    NP -> NP PP [0.31]\n",
      "    PP -> P NP [1.0]\n",
      "    V -> 'saw' [0.21]\n",
      "    V -> 'ate' [0.51]\n",
      "    V -> 'ran' [0.28]\n",
      "    N -> 'boy' [0.11]\n",
      "    N -> 'cookie' [0.12]\n",
      "    N -> 'table' [0.13]\n",
      "    N -> 'telescope' [0.14]\n",
      "    N -> 'hill' [0.5]\n",
      "    Name -> 'Jack' [0.52]\n",
      "    Name -> 'Bob' [0.48]\n",
      "    P -> 'with' [0.61]\n",
      "    P -> 'under' [0.39]\n",
      "    Det -> 'the' [0.41]\n",
      "    Det -> 'a' [0.31]\n",
      "    Det -> 'my' [0.28]\n"
     ]
    }
   ],
   "source": [
    "tokens = \"Jack saw Bob with my cookie\".split()\n",
    "grammar = toy_pcfg2\n",
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import pchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Name Jack))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP\n",
      "      (NP (Name Bob))\n",
      "      (PP (P with) (NP (Det my) (N cookie)))))) (p=6.31607e-06)\n",
      "(S\n",
      "  (NP (Name Jack))\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Name Bob)))\n",
      "    (PP (P with) (NP (Det my) (N cookie))))) (p=2.03744e-07)\n"
     ]
    }
   ],
   "source": [
    "parser = pchart.InsideChartParser(grammar)\n",
    "for t in parser.parse(tokens):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Name Jack))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP\n",
      "      (NP (Name Bob))\n",
      "      (PP (P with) (NP (Det my) (N cookie)))))) (p=6.31607e-06)\n",
      "(S\n",
      "  (NP (Name Jack))\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Name Bob)))\n",
      "    (PP (P with) (NP (Det my) (N cookie))))) (p=2.03744e-07)\n"
     ]
    }
   ],
   "source": [
    "parser = pchart.RandomChartParser(grammar)\n",
    "for t in parser.parse(tokens):\n",
    "     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Name Jack))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP\n",
      "      (NP (Name Bob))\n",
      "      (PP (P with) (NP (Det my) (N cookie)))))) (p=6.31607e-06)\n",
      "(S\n",
      "  (NP (Name Jack))\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Name Bob)))\n",
      "    (PP (P with) (NP (Det my) (N cookie))))) (p=2.03744e-07)\n"
     ]
    }
   ],
   "source": [
    "parser = pchart.UnsortedChartParser(grammar)\n",
    "for t in parser.parse(tokens):\n",
    "     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Name Jack))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP\n",
      "      (NP (Name Bob))\n",
      "      (PP (P with) (NP (Det my) (N cookie)))))) (p=6.31607e-06)\n",
      "(S\n",
      "  (NP (Name Jack))\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Name Bob)))\n",
      "    (PP (P with) (NP (Det my) (N cookie))))) (p=2.03744e-07)\n"
     ]
    }
   ],
   "source": [
    "parser = pchart.LongestChartParser(grammar)\n",
    "for t in parser.parse(tokens):\n",
    "     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = pchart.InsideChartParser(grammar, beam_size = len(tokens)+1)\n",
    "for t in parser.parse(tokens):\n",
    "     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import ViterbiParser\n",
    "tokens = \"Jack saw Bob with my cookie\".split()\n",
    "grammar = toy_pcfg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Name Jack))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP\n",
      "      (NP (Name Bob))\n",
      "      (PP (P with) (NP (Det my) (N cookie)))))) (p=6.31607e-06)\n"
     ]
    }
   ],
   "source": [
    "parser = ViterbiParser(grammar)\n",
    "for t in parser.parse(tokens):\n",
    "     print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[agr=[gender='f', number='pl'], pos='n']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.grammar import FeatStructNonterminal\n",
    "FeatStructNonterminal(\n",
    "    pos='n', agr=FeatStructNonterminal(number='pl', gender='f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VP[+fin]/NP[+pl]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeatStructNonterminal('VP[+fin]/NP[+pl]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grammar with 18 productions (start state = S[])\n",
      "    S[] -> NP[] VP[]\n",
      "    PP[] -> Prep[] NP[]\n",
      "    NP[] -> NP[] PP[]\n",
      "    VP[] -> VP[] PP[]\n",
      "    VP[] -> Verb[] NP[]\n",
      "    VP[] -> Verb[]\n",
      "    NP[] -> Det[pl=?x] Noun[pl=?x]\n",
      "    NP[] -> 'John'\n",
      "    NP[] -> 'I'\n",
      "    Det[] -> 'the'\n",
      "    Det[] -> 'my'\n",
      "    Det[-pl] -> 'a'\n",
      "    Noun[-pl] -> 'dog'\n",
      "    Noun[-pl] -> 'cookie'\n",
      "    Verb[] -> 'ate'\n",
      "    Verb[] -> 'saw'\n",
      "    Prep[] -> 'with'\n",
      "    Prep[] -> 'under'\n",
      "\n",
      "* FeatureChartParser\n",
      "Sentence: I saw John with a dog\n",
      "|.I.s.J.w.a.d.|\n",
      "|[-] . . . . .| [0:1] 'I'\n",
      "|. [-] . . . .| [1:2] 'saw'\n",
      "|. . [-] . . .| [2:3] 'John'\n",
      "|. . . [-] . .| [3:4] 'with'\n",
      "|. . . . [-] .| [4:5] 'a'\n",
      "|. . . . . [-]| [5:6] 'dog'\n",
      "|[-] . . . . .| [0:1] NP[] -> 'I' *\n",
      "|[-> . . . . .| [0:1] S[] -> NP[] * VP[] {}\n",
      "|[-> . . . . .| [0:1] NP[] -> NP[] * PP[] {}\n",
      "|. [-] . . . .| [1:2] Verb[] -> 'saw' *\n",
      "|. [-> . . . .| [1:2] VP[] -> Verb[] * NP[] {}\n",
      "|. [-] . . . .| [1:2] VP[] -> Verb[] *\n",
      "|. [-> . . . .| [1:2] VP[] -> VP[] * PP[] {}\n",
      "|[---] . . . .| [0:2] S[] -> NP[] VP[] *\n",
      "|. . [-] . . .| [2:3] NP[] -> 'John' *\n",
      "|. . [-> . . .| [2:3] S[] -> NP[] * VP[] {}\n",
      "|. . [-> . . .| [2:3] NP[] -> NP[] * PP[] {}\n",
      "|. [---] . . .| [1:3] VP[] -> Verb[] NP[] *\n",
      "|. [---> . . .| [1:3] VP[] -> VP[] * PP[] {}\n",
      "|[-----] . . .| [0:3] S[] -> NP[] VP[] *\n",
      "|. . . [-] . .| [3:4] Prep[] -> 'with' *\n",
      "|. . . [-> . .| [3:4] PP[] -> Prep[] * NP[] {}\n",
      "|. . . . [-] .| [4:5] Det[-pl] -> 'a' *\n",
      "|. . . . [-> .| [4:5] NP[] -> Det[pl=?x] * Noun[pl=?x] {?x: False}\n",
      "|. . . . . [-]| [5:6] Noun[-pl] -> 'dog' *\n",
      "|. . . . [---]| [4:6] NP[] -> Det[-pl] Noun[-pl] *\n",
      "|. . . . [--->| [4:6] S[] -> NP[] * VP[] {}\n",
      "|. . . . [--->| [4:6] NP[] -> NP[] * PP[] {}\n",
      "|. . . [-----]| [3:6] PP[] -> Prep[] NP[] *\n",
      "|. . [-------]| [2:6] NP[] -> NP[] PP[] *\n",
      "|. [---------]| [1:6] VP[] -> VP[] PP[] *\n",
      "|. [--------->| [1:6] VP[] -> VP[] * PP[] {}\n",
      "|[===========]| [0:6] S[] -> NP[] VP[] *\n",
      "|. . [------->| [2:6] S[] -> NP[] * VP[] {}\n",
      "|. . [------->| [2:6] NP[] -> NP[] * PP[] {}\n",
      "|. [---------]| [1:6] VP[] -> Verb[] NP[] *\n",
      "|. [--------->| [1:6] VP[] -> VP[] * PP[] {}\n",
      "|[===========]| [0:6] S[] -> NP[] VP[] *\n",
      "(S[]\n",
      "  (NP[] I)\n",
      "  (VP[]\n",
      "    (VP[] (Verb[] saw) (NP[] John))\n",
      "    (PP[] (Prep[] with) (NP[] (Det[-pl] a) (Noun[-pl] dog)))))\n",
      "(S[]\n",
      "  (NP[] I)\n",
      "  (VP[]\n",
      "    (Verb[] saw)\n",
      "    (NP[]\n",
      "      (NP[] John)\n",
      "      (PP[] (Prep[] with) (NP[] (Det[-pl] a) (Noun[-pl] dog))))))\n"
     ]
    }
   ],
   "source": [
    "nltk.parse.featurechart.demo(print_times=False,\n",
    "                              print_grammar=True,\n",
    "                              parser=nltk.parse.featurechart.FeatureChartParser,\n",
    "                              sent='I saw John with a dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
