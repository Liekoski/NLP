{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d33977",
   "metadata": {},
   "source": [
    "В данном задании нам нужно сделать из выборки (GSD_train.txt) библиотеку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec9bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a286d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sequential\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ce56b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:49: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:49: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\smirn\\AppData\\Local\\Temp\\ipykernel_2340\\3728504035.py:49: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif pos is 'ADJF' and len(pos) <= 4:\n"
     ]
    }
   ],
   "source": [
    "def words_stats(sents, name = \" \"):\n",
    "\n",
    "    words = [] \n",
    "\n",
    "    for sent in sents:\n",
    "        for word_pos in sent:\n",
    "            words.append(word_pos[0])\n",
    "\n",
    "    words_lens = [len(word) for word in words] # Длины всех слов в корпусе\n",
    "    mean_words = round(statistics.mean(words_lens), 2)\n",
    "    less_than_4 = len([i for i in words_lens if i < 4])\n",
    "    more_than_8 = len([j for j in words_lens if j > 8])\n",
    "\n",
    "    print(\"Средняя длина слова в корпусе \" + name + \" = \" + str(mean_words))\n",
    "    print(\"Количество слов меньше 4-х символов в корпусе \" + name + \" = \" + str(less_than_4) + \" (\" +\n",
    "          str(round(less_than_4 / len(words)*100, 2)) + \"%)\")\n",
    "    print(\"Количество слов больше 8-и символов в корпусе \" + name + \" = \" + str(more_than_8)+ \" (\" +\n",
    "          str(round(more_than_8/ len(words)*100, 2)) + \"%)\")\n",
    "\n",
    "\n",
    "def go_thru_loop(train, test):\n",
    "    for i in range(-5,-1):\n",
    "        for j in range(4):\n",
    "            if -i+j > 6:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Тренировка тэггера...\")\n",
    "                print(\"Длина суффикса \", i*-1)\n",
    "                print(\"Минимальная стемма \", j)\n",
    "                tagger = sequential.AffixTagger(train=train, affix_length=i,\n",
    "                                                          min_stem_length=j, verbose=False)\n",
    "                print(\"Результат:\", round(tagger.evaluate(test), 3)*100, \"%\")\n",
    "                print('-----------------------------')\n",
    "\n",
    "def rmv_irr_tokens(sents):\n",
    "\n",
    "    print('--------------------')\n",
    "    print(\"Количество словоупотреблений до чистки: \" + str(sum(len(i) for i in sents)))\n",
    "    num_of_irr = 0\n",
    "\n",
    "    for i in range(6):\n",
    "        for sent in sents:\n",
    "            for word_pos in sent:\n",
    "                pos = list(word_pos)[1].split(',')[0]\n",
    "                if pos in ['PNCT', 'NUMR', 'PRTF', 'PRCL', 'PREP', 'UNKN', 'CONJ', 'PRTS',\n",
    "                                  'sing', 'plur', 'neut', '', 'masc', 'INTJ']:\n",
    "                    sent.remove(word_pos)\n",
    "                    num_of_irr += 1\n",
    "                elif pos is 'ADJF' and len(pos) <= 4:\n",
    "                    sent.remove(word_pos)\n",
    "                    num_of_irr += 1\n",
    "            if len(sent) == 0:\n",
    "                sents.remove(sent)\n",
    "\n",
    "    print(\"Количество удаленных токенов: \" + str(num_of_irr))\n",
    "    print(\"Количество словоупотреблений после чистки: \" + str(sum(len(i) for i in sents)))\n",
    "    print('--------------------')\n",
    "\n",
    "def full_morph_to_pos(sents):\n",
    "\n",
    "    sent_index = 0\n",
    "    for sent in sents:\n",
    "        word_pos_index = 0\n",
    "        for word_pos in sent:\n",
    "            word_pos = list(word_pos)\n",
    "            sents[sent_index][word_pos_index] = list(sents[sent_index][word_pos_index])\n",
    "            sents[sent_index][word_pos_index][1] = word_pos[1].split(',')[0]\n",
    "            sents[sent_index][word_pos_index] = tuple(sents[sent_index][word_pos_index])\n",
    "            word_pos_index += 1\n",
    "        sent_index += 1\n",
    "\n",
    "\n",
    "def apply_tagger_to_list(tagger, word_list, counter = 0):\n",
    "\n",
    "    print(\"----------\")\n",
    "    for tok, tag in tagger.tag(word_list):\n",
    "        if tag is None:\n",
    "            counter += 1\n",
    "        print(\"(%s, %s), \" % (tok, tag))\n",
    "    print(\"----------\")\n",
    "    print(\"Неопознанных слов: %d\" % counter)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41a3465",
   "metadata": {},
   "source": [
    "Направляем на файл и делаем из него словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b09d622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Начальный</td>\n",
       "      <td>начальный</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJL</td>\n",
       "      <td>Case=Nom|Degree=Pos|Gender=Masc|Number=Sing</td>\n",
       "      <td>2</td>\n",
       "      <td>amod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ролик</td>\n",
       "      <td>ролик</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing</td>\n",
       "      <td>17</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>_</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>или</td>\n",
       "      <td>или</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>cc</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>опенинг</td>\n",
       "      <td>опенинг</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing</td>\n",
       "      <td>2</td>\n",
       "      <td>conj</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96956</th>\n",
       "      <td>8</td>\n",
       "      <td>и</td>\n",
       "      <td>и</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>_</td>\n",
       "      <td>9</td>\n",
       "      <td>cc</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96957</th>\n",
       "      <td>9</td>\n",
       "      <td>разбит</td>\n",
       "      <td>разбить</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBNH</td>\n",
       "      <td>Animacy=Inan|Aspect=Perf|Case=Nom|Gender=Masc|...</td>\n",
       "      <td>6</td>\n",
       "      <td>conj</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96958</th>\n",
       "      <td>10</td>\n",
       "      <td>колхозный</td>\n",
       "      <td>колхозный</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJL</td>\n",
       "      <td>Case=Nom|Degree=Pos|Gender=Masc|Number=Sing</td>\n",
       "      <td>11</td>\n",
       "      <td>amod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96959</th>\n",
       "      <td>11</td>\n",
       "      <td>сад</td>\n",
       "      <td>сад</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing</td>\n",
       "      <td>9</td>\n",
       "      <td>nsubj:pass</td>\n",
       "      <td>_</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96960</th>\n",
       "      <td>12</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>_</td>\n",
       "      <td>6</td>\n",
       "      <td>punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96961 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1          2      3     4  \\\n",
       "0       1  Начальный  начальный    ADJ   JJL   \n",
       "1       2      ролик      ролик   NOUN    NN   \n",
       "2       3          ,          ,  PUNCT     ,   \n",
       "3       4        или        или  CCONJ    CC   \n",
       "4       5    опенинг    опенинг   NOUN    NN   \n",
       "...    ..        ...        ...    ...   ...   \n",
       "96956   8          и          и  CCONJ    CC   \n",
       "96957   9     разбит    разбить   VERB  VBNH   \n",
       "96958  10  колхозный  колхозный    ADJ   JJL   \n",
       "96959  11        сад        сад   NOUN    NN   \n",
       "96960  12          .          .  PUNCT     .   \n",
       "\n",
       "                                                       5   6           7  8  \\\n",
       "0            Case=Nom|Degree=Pos|Gender=Masc|Number=Sing   2        amod  _   \n",
       "1          Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing  17       nsubj  _   \n",
       "2                                                      _   5       punct  _   \n",
       "3                                                      _   5          cc  _   \n",
       "4          Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing   2        conj  _   \n",
       "...                                                  ...  ..         ... ..   \n",
       "96956                                                  _   9          cc  _   \n",
       "96957  Animacy=Inan|Aspect=Perf|Case=Nom|Gender=Masc|...   6        conj  _   \n",
       "96958        Case=Nom|Degree=Pos|Gender=Masc|Number=Sing  11        amod  _   \n",
       "96959      Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing   9  nsubj:pass  _   \n",
       "96960                                                  _   6       punct  _   \n",
       "\n",
       "                   9  \n",
       "0                  _  \n",
       "1      SpaceAfter=No  \n",
       "2                  _  \n",
       "3                  _  \n",
       "4                  _  \n",
       "...              ...  \n",
       "96956              _  \n",
       "96957              _  \n",
       "96958              _  \n",
       "96959  SpaceAfter=No  \n",
       "96960              _  \n",
       "\n",
       "[96961 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = r'GSD_train.txt'\n",
    "df = pd.read_csv(data, delimiter = \"\\t\", header=None) # Чтение csv\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57ab131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>начальный</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ролик</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>или</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>опенинг</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96956</th>\n",
       "      <td>8</td>\n",
       "      <td>и</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96957</th>\n",
       "      <td>9</td>\n",
       "      <td>разбить</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96958</th>\n",
       "      <td>10</td>\n",
       "      <td>колхозный</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96959</th>\n",
       "      <td>11</td>\n",
       "      <td>сад</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96960</th>\n",
       "      <td>12</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96961 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          2      3\n",
       "0       1  начальный    ADJ\n",
       "1       2      ролик   NOUN\n",
       "2       3          ,  PUNCT\n",
       "3       4        или  CCONJ\n",
       "4       5    опенинг   NOUN\n",
       "...    ..        ...    ...\n",
       "96956   8          и  CCONJ\n",
       "96957   9    разбить   VERB\n",
       "96958  10  колхозный    ADJ\n",
       "96959  11        сад   NOUN\n",
       "96960  12          .  PUNCT\n",
       "\n",
       "[96961 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tuple = df.drop(columns = [1, 4, 5, 6, 7, 8, 9], axis = 1)\n",
    "my_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcbb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tuple_dict = my_tuple.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "355b9671",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = []\n",
    "mega_ar = []\n",
    "for i in my_tuple_dict[2]:\n",
    "  if my_tuple_dict[2][i] == ',' or my_tuple_dict[2][i] == '.':\n",
    "    mega_ar.append(ar)\n",
    "    ar = []\n",
    "    continue\n",
    "  ar.append((my_tuple_dict[2][i], my_tuple_dict[3][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5574f121",
   "metadata": {},
   "source": [
    "Считаем количество единиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23b36dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11306"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mega_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e2f204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(mega_ar) * 0.9)\n",
    "train_sents = mega_ar[:127980]\n",
    "test_sents = mega_ar[127980:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d76d9d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Количество словоупотреблений до чистки: 85655\n",
      "Количество удаленных токенов: 0\n",
      "Количество словоупотреблений после чистки: 85655\n",
      "--------------------\n",
      "--------------------\n",
      "Количество словоупотреблений до чистки: 0\n",
      "Количество удаленных токенов: 0\n",
      "Количество словоупотреблений после чистки: 0\n",
      "--------------------\n",
      "Средняя длина слова в корпусе sents_train = 5.69\n",
      "Количество слов меньше 4-х символов в корпусе sents_train = 27700 (32.34%)\n",
      "Количество слов больше 8-и символов в корпусе sents_train = 19254 (22.48%)\n",
      "--------------------------\n",
      "Средняя длина слова в корпусе sents_train = 5.69\n",
      "Количество слов меньше 4-х символов в корпусе sents_train = 27700 (32.34%)\n",
      "Количество слов больше 8-и символов в корпусе sents_train = 19254 (22.48%)\n",
      "|||||||||||||||||||||||||\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  5\n",
      "Минимальная стемма  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smirn\\AppData\\Local\\Temp\\ipykernel_2340\\3728504035.py:32: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(\"Результат:\", round(tagger.evaluate(test), 3)*100, \"%\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат: 57.199999999999996 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  5\n",
      "Минимальная стемма  1\n",
      "Результат: 47.8 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  0\n",
      "Результат: 65.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  1\n",
      "Результат: 56.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  2\n",
      "Результат: 47.099999999999994 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  0\n",
      "Результат: 69.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  1\n",
      "Результат: 62.1 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  2\n",
      "Результат: 54.1 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  3\n",
      "Результат: 45.7 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  0\n",
      "Результат: 67.80000000000001 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  1\n",
      "Результат: 60.9 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  2\n",
      "Результат: 55.50000000000001 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  3\n",
      "Результат: 49.3 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "mega_ar = train_sents\n",
    "\n",
    "\n",
    "rmv_irr_tokens(train_sents) # Удаляем все слова, кроме {'GRND', 'ADJS', 'VERB', 'PRED', 'INFN', 'COMP', 'ADVB', 'ADJF', 'NOUN'}\n",
    "rmv_irr_tokens(test_sents)\n",
    "\n",
    "words_stats(train_sents, name = \"sents_train\") # Длины слов после чистки\n",
    "print('--------------------------')\n",
    "words_stats(train_sents, name = \"sents_train\")\n",
    "\n",
    "print(\"|||||||||||||||||||||||||\")\n",
    "go_thru_loop(train_sents, train_sents) # После удаления нерелевантных слов и знаков (результаты улучшились)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "453ec4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Количество словоупотреблений до чистки: 85655\n",
      "Количество удаленных токенов: 0\n",
      "Количество словоупотреблений после чистки: 85655\n",
      "--------------------\n",
      "--------------------\n",
      "Оставшиеся метки:  {'VERB', 'NOUN', 'SCONJ', 'AUX', 'CCONJ', 'X', 'ADJ', 'ADP', 'PRON', 'ADV', 'DET', 'PROPN', 'NUM', 'PUNCT', 'PART', 'SYM'}\n",
      "--------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  5\n",
      "Минимальная стемма  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smirn\\AppData\\Local\\Temp\\ipykernel_2340\\3728504035.py:32: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(\"Результат:\", round(tagger.evaluate(test), 3)*100, \"%\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат: 57.199999999999996 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  5\n",
      "Минимальная стемма  1\n",
      "Результат: 47.8 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  0\n",
      "Результат: 65.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  1\n",
      "Результат: 56.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  2\n",
      "Результат: 47.099999999999994 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  0\n",
      "Результат: 69.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  1\n",
      "Результат: 62.1 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  2\n",
      "Результат: 54.1 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  3\n",
      "Результат: 45.7 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  0\n",
      "Результат: 67.80000000000001 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  1\n",
      "Результат: 60.9 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  2\n",
      "Результат: 55.50000000000001 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  3\n",
      "Результат: 49.3 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "rmv_irr_tokens(train_sents)\n",
    "\n",
    "\n",
    "full_morph_to_pos(train_sents) #Теперь тренируем POS тэггер\n",
    "\n",
    "\n",
    "pos_list = []\n",
    "for sent in train_sents:\n",
    "    for word_pos in sent:\n",
    "        pos = word_pos[1]\n",
    "        pos_list.append(pos)\n",
    "print('--------------------')\n",
    "print(\"Оставшиеся метки: \", set(pos_list))\n",
    "print('--------------------')\n",
    "\n",
    "go_thru_loop(train_sents, train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "104dbcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Количество словоупотреблений до чистки: 85655\n",
      "Количество удаленных токенов: 0\n",
      "Количество словоупотреблений после чистки: 85655\n",
      "--------------------\n",
      "----------\n",
      "(фонетика, NOUN), \n",
      "(теггер, PROPN), \n",
      "(глокая, PROPN), \n",
      "(куздра, NOUN), \n",
      "(краб, NOUN), \n",
      "(радовался, None), \n",
      "(хороший, ADJ), \n",
      "(этот, DET), \n",
      "(умереть, VERB), \n",
      "(быстро, ADV), \n",
      "----------\n",
      "Неопознанных слов: 1\n",
      "\n",
      "----------\n",
      "(фонетика, NOUN), \n",
      "(теггер, PROPN), \n",
      "(глокая, PROPN), \n",
      "(куздра, NOUN), \n",
      "(краб, NOUN), \n",
      "(радовался, None), \n",
      "(хороший, ADJ), \n",
      "(этот, DET), \n",
      "(умереть, VERB), \n",
      "(быстро, ADV), \n",
      "----------\n",
      "Неопознанных слов: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_list  = [\"фонетика\", \"теггер\", \"глокая\", \"куздра\", \"краб\", \"радовался\", \"хороший\", \"этот\", \"умереть\", \"быстро\"]\n",
    "\n",
    "test_sents = train_sents\n",
    "\n",
    "\n",
    "rmv_irr_tokens(train_sents)\n",
    "test_full_tagger = sequential.AffixTagger(train=train_sents, affix_length=-3, min_stem_length=0, verbose=False)\n",
    "apply_tagger_to_list(test_full_tagger, cool_list)\n",
    "\n",
    "\n",
    "full_morph_to_pos(train_sents)\n",
    "test_pos_tagger = sequential.AffixTagger(train=train_sents, affix_length=-3, min_stem_length=0, verbose=False)\n",
    "apply_tagger_to_list(test_pos_tagger, cool_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b26d82e",
   "metadata": {},
   "source": [
    "Делаем n-граммные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1ed561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "trigram_tagger = nltk.TrigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "974c1fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram:\t 0.9840756523261923 \n",
      "Bigram:\t\t 0.9566166598564007 \n",
      "Trigram:\t 0.9562897670889031\n"
     ]
    }
   ],
   "source": [
    "print('Unigram:\\t', unigram_tagger.accuracy(train_sents),\n",
    "      '\\nBigram:\\t\\t', bigram_tagger.accuracy(train_sents),\n",
    "      '\\nTrigram:\\t', trigram_tagger.accuracy(train_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951bbf3b",
   "metadata": {},
   "source": [
    "СОздаём файл, куда записываем точное количество n-граммных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2e7b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('N-gramm.txt', 'w+')\n",
    "f.write(str(unigram_tagger))\n",
    "f.write(str(bigram_tagger))\n",
    "f.write(str(trigram_tagger))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6059b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
