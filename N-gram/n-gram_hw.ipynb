{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d5bba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39ca0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9aa358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fba27e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sequential\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61ef1fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:49: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:49: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\smirn\\AppData\\Local\\Temp\\ipykernel_4604\\2483682145.py:49: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif pos is 'ADJF' and len(pos) <= 4:\n"
     ]
    }
   ],
   "source": [
    "def words_stats(sents, name = \" \"):\n",
    "\n",
    "    words = [] \n",
    "\n",
    "    for sent in sents:\n",
    "        for word_pos in sent:\n",
    "            words.append(word_pos[0])\n",
    "\n",
    "    words_lens = [len(word) for word in words] # Длины всех слов в корпусе\n",
    "    mean_words = round(statistics.mean(words_lens), 2)\n",
    "    less_than_4 = len([i for i in words_lens if i < 4])\n",
    "    more_than_8 = len([j for j in words_lens if j > 8])\n",
    "\n",
    "    print(\"Средняя длина слова в корпусе \" + name + \" = \" + str(mean_words))\n",
    "    print(\"Количество слов меньше 4-х символов в корпусе \" + name + \" = \" + str(less_than_4) + \" (\" +\n",
    "          str(round(less_than_4 / len(words)*100, 2)) + \"%)\")\n",
    "    print(\"Количество слов больше 8-и символов в корпусе \" + name + \" = \" + str(more_than_8)+ \" (\" +\n",
    "          str(round(more_than_8/ len(words)*100, 2)) + \"%)\")\n",
    "\n",
    "\n",
    "def go_thru_loop(train, test):\n",
    "    for i in range(-5,-1):\n",
    "        for j in range(4):\n",
    "            if -i+j > 6:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Тренировка тэггера...\")\n",
    "                print(\"Длина суффикса \", i*-1)\n",
    "                print(\"Минимальная стемма \", j)\n",
    "                tagger = sequential.AffixTagger(train=train, affix_length=i,\n",
    "                                                          min_stem_length=j, verbose=False)\n",
    "                print(\"Результат:\", round(tagger.evaluate(test), 3)*100, \"%\")\n",
    "                print('-----------------------------')\n",
    "\n",
    "def rmv_irr_tokens(sents):\n",
    "\n",
    "    print('--------------------')\n",
    "    print(\"Количество словоупотреблений до чистки: \" + str(sum(len(i) for i in sents)))\n",
    "    num_of_irr = 0\n",
    "\n",
    "    for i in range(6):\n",
    "        for sent in sents:\n",
    "            for word_pos in sent:\n",
    "                pos = list(word_pos)[1].split(',')[0]\n",
    "                if pos in ['PNCT', 'NUMR', 'PRTF', 'PRCL', 'PREP', 'UNKN', 'CONJ', 'PRTS',\n",
    "                                  'sing', 'plur', 'neut', '', 'masc', 'INTJ']:\n",
    "                    sent.remove(word_pos)\n",
    "                    num_of_irr += 1\n",
    "                elif pos is 'ADJF' and len(pos) <= 4:\n",
    "                    sent.remove(word_pos)\n",
    "                    num_of_irr += 1\n",
    "            if len(sent) == 0:\n",
    "                sents.remove(sent)\n",
    "\n",
    "    print(\"Количество удаленных токенов: \" + str(num_of_irr))\n",
    "    print(\"Количество словоупотреблений после чистки: \" + str(sum(len(i) for i in sents)))\n",
    "    print('--------------------')\n",
    "\n",
    "def full_morph_to_pos(sents):\n",
    "\n",
    "    sent_index = 0\n",
    "    for sent in sents:\n",
    "        word_pos_index = 0\n",
    "        for word_pos in sent:\n",
    "            word_pos = list(word_pos)\n",
    "            sents[sent_index][word_pos_index] = list(sents[sent_index][word_pos_index])\n",
    "            sents[sent_index][word_pos_index][1] = word_pos[1].split(',')[0]\n",
    "            sents[sent_index][word_pos_index] = tuple(sents[sent_index][word_pos_index])\n",
    "            word_pos_index += 1\n",
    "        sent_index += 1\n",
    "\n",
    "\n",
    "def apply_tagger_to_list(tagger, word_list, counter = 0):\n",
    "\n",
    "    print(\"----------\")\n",
    "    for tok, tag in tagger.tag(word_list):\n",
    "        if tag == None:\n",
    "            counter += 1\n",
    "        print(\"(%s, %s), \" % (tok, tag))\n",
    "    print(\"----------\")\n",
    "    print(\"Неопознанных слов: %d\" % counter)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a223c13b",
   "metadata": {},
   "source": [
    "Здесь мы делаем собственную библиотеку из размеченного текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd9bafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r'GSD_train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c82d6262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Начальный</td>\n",
       "      <td>начальный</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJL</td>\n",
       "      <td>Case=Nom|Degree=Pos|Gender=Masc|Number=Sing</td>\n",
       "      <td>2</td>\n",
       "      <td>amod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ролик</td>\n",
       "      <td>ролик</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing</td>\n",
       "      <td>17</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>_</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>или</td>\n",
       "      <td>или</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>_</td>\n",
       "      <td>5</td>\n",
       "      <td>cc</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>опенинг</td>\n",
       "      <td>опенинг</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing</td>\n",
       "      <td>2</td>\n",
       "      <td>conj</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96956</th>\n",
       "      <td>8</td>\n",
       "      <td>и</td>\n",
       "      <td>и</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>_</td>\n",
       "      <td>9</td>\n",
       "      <td>cc</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96957</th>\n",
       "      <td>9</td>\n",
       "      <td>разбит</td>\n",
       "      <td>разбить</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBNH</td>\n",
       "      <td>Animacy=Inan|Aspect=Perf|Case=Nom|Gender=Masc|...</td>\n",
       "      <td>6</td>\n",
       "      <td>conj</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96958</th>\n",
       "      <td>10</td>\n",
       "      <td>колхозный</td>\n",
       "      <td>колхозный</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJL</td>\n",
       "      <td>Case=Nom|Degree=Pos|Gender=Masc|Number=Sing</td>\n",
       "      <td>11</td>\n",
       "      <td>amod</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96959</th>\n",
       "      <td>11</td>\n",
       "      <td>сад</td>\n",
       "      <td>сад</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing</td>\n",
       "      <td>9</td>\n",
       "      <td>nsubj:pass</td>\n",
       "      <td>_</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96960</th>\n",
       "      <td>12</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>_</td>\n",
       "      <td>6</td>\n",
       "      <td>punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96961 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1          2      3     4  \\\n",
       "0       1  Начальный  начальный    ADJ   JJL   \n",
       "1       2      ролик      ролик   NOUN    NN   \n",
       "2       3          ,          ,  PUNCT     ,   \n",
       "3       4        или        или  CCONJ    CC   \n",
       "4       5    опенинг    опенинг   NOUN    NN   \n",
       "...    ..        ...        ...    ...   ...   \n",
       "96956   8          и          и  CCONJ    CC   \n",
       "96957   9     разбит    разбить   VERB  VBNH   \n",
       "96958  10  колхозный  колхозный    ADJ   JJL   \n",
       "96959  11        сад        сад   NOUN    NN   \n",
       "96960  12          .          .  PUNCT     .   \n",
       "\n",
       "                                                       5   6           7  8  \\\n",
       "0            Case=Nom|Degree=Pos|Gender=Masc|Number=Sing   2        amod  _   \n",
       "1          Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing  17       nsubj  _   \n",
       "2                                                      _   5       punct  _   \n",
       "3                                                      _   5          cc  _   \n",
       "4          Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing   2        conj  _   \n",
       "...                                                  ...  ..         ... ..   \n",
       "96956                                                  _   9          cc  _   \n",
       "96957  Animacy=Inan|Aspect=Perf|Case=Nom|Gender=Masc|...   6        conj  _   \n",
       "96958        Case=Nom|Degree=Pos|Gender=Masc|Number=Sing  11        amod  _   \n",
       "96959      Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing   9  nsubj:pass  _   \n",
       "96960                                                  _   6       punct  _   \n",
       "\n",
       "                   9  \n",
       "0                  _  \n",
       "1      SpaceAfter=No  \n",
       "2                  _  \n",
       "3                  _  \n",
       "4                  _  \n",
       "...              ...  \n",
       "96956              _  \n",
       "96957              _  \n",
       "96958              _  \n",
       "96959  SpaceAfter=No  \n",
       "96960              _  \n",
       "\n",
       "[96961 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data, delimiter = \"\\t\", header=None) # Чтение csv\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8231e9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>начальный</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ролик</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>или</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>опенинг</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96956</th>\n",
       "      <td>8</td>\n",
       "      <td>и</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96957</th>\n",
       "      <td>9</td>\n",
       "      <td>разбить</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96958</th>\n",
       "      <td>10</td>\n",
       "      <td>колхозный</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96959</th>\n",
       "      <td>11</td>\n",
       "      <td>сад</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96960</th>\n",
       "      <td>12</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96961 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          2      3\n",
       "0       1  начальный    ADJ\n",
       "1       2      ролик   NOUN\n",
       "2       3          ,  PUNCT\n",
       "3       4        или  CCONJ\n",
       "4       5    опенинг   NOUN\n",
       "...    ..        ...    ...\n",
       "96956   8          и  CCONJ\n",
       "96957   9    разбить   VERB\n",
       "96958  10  колхозный    ADJ\n",
       "96959  11        сад   NOUN\n",
       "96960  12          .  PUNCT\n",
       "\n",
       "[96961 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tuple = df.drop(columns = [1,4, 5, 6, 7, 8, 9], axis = 1)\n",
    "my_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7bff02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tuple_dict = my_tuple.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "449196fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = []\n",
    "mega_ar = []\n",
    "for i in my_tuple_dict[2]:\n",
    "  if my_tuple_dict[2][i] == ',' or my_tuple_dict[2][i] == '.':\n",
    "    mega_ar.append(ar)\n",
    "    ar = []\n",
    "    continue\n",
    "  ar.append((my_tuple_dict[2][i], my_tuple_dict[3][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b268a51",
   "metadata": {},
   "source": [
    "Считаем количество лексических единиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0456f0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11306"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mega_ar) # получение длины словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "586b4837",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(mega_ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "189bc58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11306\n"
     ]
    }
   ],
   "source": [
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47b30f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = mega_ar[:size]\n",
    "test_sents = mega_ar[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4a2f918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Количество словоупотреблений до чистки: 85655\n",
      "Количество удаленных токенов: 0\n",
      "Количество словоупотреблений после чистки: 85655\n",
      "--------------------\n",
      "--------------------\n",
      "Количество словоупотреблений до чистки: 0\n",
      "Количество удаленных токенов: 0\n",
      "Количество словоупотреблений после чистки: 0\n",
      "--------------------\n",
      "Средняя длина слова в корпусе sents_train = 5.69\n",
      "Количество слов меньше 4-х символов в корпусе sents_train = 27700 (32.34%)\n",
      "Количество слов больше 8-и символов в корпусе sents_train = 19254 (22.48%)\n",
      "--------------------------\n",
      "Средняя длина слова в корпусе sents_train = 5.69\n",
      "Количество слов меньше 4-х символов в корпусе sents_train = 27700 (32.34%)\n",
      "Количество слов больше 8-и символов в корпусе sents_train = 19254 (22.48%)\n",
      "|||||||||||||||||||||||||\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  5\n",
      "Минимальная стемма  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smirn\\AppData\\Local\\Temp\\ipykernel_4604\\2483682145.py:32: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(\"Результат:\", round(tagger.evaluate(test), 3)*100, \"%\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат: 57.199999999999996 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  5\n",
      "Минимальная стемма  1\n",
      "Результат: 47.8 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  0\n",
      "Результат: 65.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  1\n",
      "Результат: 56.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  2\n",
      "Результат: 47.099999999999994 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  0\n",
      "Результат: 69.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  1\n",
      "Результат: 62.1 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  2\n",
      "Результат: 54.1 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  3\n",
      "Результат: 45.7 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  0\n",
      "Результат: 67.80000000000001 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  1\n",
      "Результат: 60.9 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  2\n",
      "Результат: 55.50000000000001 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  3\n",
      "Результат: 49.3 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "#mega_ar = train\n",
    "\n",
    "#mega_ar = test\n",
    "\n",
    "rmv_irr_tokens(train_sents) # Удаляем все слова, кроме {'GRND', 'ADJS', 'VERB', 'PRED', 'INFN', 'COMP', 'ADVB', 'ADJF', 'NOUN'}\n",
    "rmv_irr_tokens(test_sents)\n",
    "\n",
    "words_stats(train_sents, name = \"sents_train\") # Длины слов после чистки\n",
    "print('--------------------------')\n",
    "words_stats(train_sents, name = \"sents_train\")\n",
    "\n",
    "print(\"|||||||||||||||||||||||||\")\n",
    "go_thru_loop(train_sents, train_sents) # После удаления нерелевантных слов и знаков (результаты улучшились)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df3c00a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Количество словоупотреблений до чистки: 85655\n",
      "Количество удаленных токенов: 0\n",
      "Количество словоупотреблений после чистки: 85655\n",
      "--------------------\n",
      "--------------------\n",
      "Количество словоупотреблений до чистки: 0\n",
      "Количество удаленных токенов: 0\n",
      "Количество словоупотреблений после чистки: 0\n",
      "--------------------\n",
      "--------------------\n",
      "Оставшиеся метки:  {'ADJ', 'DET', 'SCONJ', 'VERB', 'PART', 'PRON', 'AUX', 'X', 'NUM', 'SYM', 'PROPN', 'PUNCT', 'NOUN', 'ADP', 'ADV', 'CCONJ'}\n",
      "--------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  5\n",
      "Минимальная стемма  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smirn\\AppData\\Local\\Temp\\ipykernel_4604\\2483682145.py:32: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  print(\"Результат:\", round(tagger.evaluate(test), 3)*100, \"%\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат: 57.199999999999996 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  5\n",
      "Минимальная стемма  1\n",
      "Результат: 47.8 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  0\n",
      "Результат: 65.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  1\n",
      "Результат: 56.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  4\n",
      "Минимальная стемма  2\n",
      "Результат: 47.099999999999994 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  0\n",
      "Результат: 69.3 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  1\n",
      "Результат: 62.1 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  2\n",
      "Результат: 54.1 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  3\n",
      "Минимальная стемма  3\n",
      "Результат: 45.7 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  0\n",
      "Результат: 67.80000000000001 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  1\n",
      "Результат: 60.9 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  2\n",
      "Результат: 55.50000000000001 %\n",
      "-----------------------------\n",
      "Тренировка тэггера...\n",
      "Длина суффикса  2\n",
      "Минимальная стемма  3\n",
      "Результат: 49.3 %\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "rmv_irr_tokens(train_sents)\n",
    "rmv_irr_tokens(test_sents)\n",
    "\n",
    "full_morph_to_pos(train_sents) #Теперь тренируем POS тэггер\n",
    "full_morph_to_pos(test_sents)\n",
    "\n",
    "pos_list = []\n",
    "for sent in train_sents:\n",
    "    for word_pos in sent:\n",
    "        pos = word_pos[1]\n",
    "        pos_list.append(pos)\n",
    "print('--------------------')\n",
    "print(\"Оставшиеся метки: \", set(pos_list))\n",
    "print('--------------------')\n",
    "\n",
    "go_thru_loop(train_sents, train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b8bb36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Количество словоупотреблений до чистки: 85655\n",
      "Количество удаленных токенов: 0\n",
      "Количество словоупотреблений после чистки: 85655\n",
      "--------------------\n",
      "----------\n",
      "(фонетика, NOUN), \n",
      "(теггер, PROPN), \n",
      "(глокая, PROPN), \n",
      "(куздра, NOUN), \n",
      "(краб, NOUN), \n",
      "(радовался, None), \n",
      "(хороший, ADJ), \n",
      "(этот, DET), \n",
      "(умереть, VERB), \n",
      "(быстро, ADV), \n",
      "----------\n",
      "Неопознанных слов: 1\n",
      "\n",
      "----------\n",
      "(фонетика, NOUN), \n",
      "(теггер, PROPN), \n",
      "(глокая, PROPN), \n",
      "(куздра, NOUN), \n",
      "(краб, NOUN), \n",
      "(радовался, None), \n",
      "(хороший, ADJ), \n",
      "(этот, DET), \n",
      "(умереть, VERB), \n",
      "(быстро, ADV), \n",
      "----------\n",
      "Неопознанных слов: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_list  = [\"фонетика\", \"теггер\", \"глокая\", \"куздра\", \"краб\", \"радовался\", \"хороший\", \"этот\", \"умереть\", \"быстро\"]\n",
    "\n",
    "test_sents = train_sents\n",
    "\n",
    "\n",
    "rmv_irr_tokens(train_sents)\n",
    "test_full_tagger = sequential.AffixTagger(train=train_sents, affix_length=-3, min_stem_length=0, verbose=False)\n",
    "apply_tagger_to_list(test_full_tagger, cool_list)\n",
    "\n",
    "\n",
    "full_morph_to_pos(train_sents)\n",
    "test_pos_tagger = sequential.AffixTagger(train=train_sents, affix_length=-3, min_stem_length=0, verbose=False)\n",
    "apply_tagger_to_list(test_pos_tagger, cool_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe38e06",
   "metadata": {},
   "source": [
    "Пытаемся сделать n-граммные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d57f6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9134305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import BigramTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd82b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_sents = mega_ar[:size]\n",
    "#test_sents = mega_ar[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6cdc48e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m unigram_tagger \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mUnigramTagger(train_sents)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tag\\sequential.py:363\u001b[0m, in \u001b[0;36mUnigramTagger.__init__\u001b[1;34m(self, train, model, backoff, cutoff, verbose)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, backoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m1\u001b[39m, train, model, backoff, cutoff, verbose)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tag\\sequential.py:296\u001b[0m, in \u001b[0;36mNgramTagger.__init__\u001b[1;34m(self, n, train, model, backoff, cutoff, verbose)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model, backoff)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[1;32m--> 296\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train(train, cutoff, verbose)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tag\\sequential.py:179\u001b[0m, in \u001b[0;36mContextTagger._train\u001b[1;34m(self, tagged_corpus, cutoff, verbose)\u001b[0m\n\u001b[0;32m    177\u001b[0m fd \u001b[38;5;241m=\u001b[39m ConditionalFreqDist()\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m tagged_corpus:\n\u001b[1;32m--> 179\u001b[0m     tokens, tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msentence)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, (token, tag) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sentence):\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;66;03m# Record the event.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m         token_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "bigram_tagger = nltk.BigramTagger(train_sents)\n",
    "trigram_tagger = nltk.TrigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cafdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mega_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a487ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d34005b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
